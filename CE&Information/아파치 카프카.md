# Kafka

- 데이터를 전송하는 source application, 데이터를 받는 target application
- 처음에는 단방향 통신사용, 
- 시간이 지나면서 source 와 target의 수가 증가 됨

- 라인이 매우 복잡해짐 -> 배포와 장애에 대응이 어렵다



- Source -> kafka -> Target
- 유연한 que 역할
- 빅데이터 처리에 사용

```mermaid
graph LR

    A[<font color=white> Source Application] -- Link text --> B((Circle)) -- text --> C
    B(Kafka<p>-Topic1<br>-Topic2<br>-Topic3</P>)
    C[<font color=white> Target Application]
    
    style A fill:#000000,strock-width:8px,stroke:#3AA
    style B fill:#FFFFFF,stroke-width:6px,stroke-dasharray:1,10
    style C fill:#000000
```

## kafka topic

- 다양한 데이터가 들어갈 수 있는데, 그 데이터가 들어가는 공간을 토픽이라고 함
- 일반적인 AMQP와는 다르게 동작
- 토픽을 여러개 생성할 수 있다.

- 토픽은 데이터베이스의 테이블이나, 파일시스템의 폴더와 유사한 성질을 가지고 있다

- 프로듀서가 토픽에 데이터를 넣게되고, 컨슈머는 데이터를 가져간다

- 목적에 따라 이름을 가질 수 있다(무슨 데이터를 담는지 명확히)

  

#### 파티션

- 하나의 토픽은 여러개의 파티션으로 구성될 수 있으며, 첫번째 파티션번호는 0번 부터 시작

- 하나의 파티션은 큐와 같이 내부에 데이터가 파티션 끝에서 부터 차곡차곡 쌓임

- 해당 토픽에 카프카 컨슈머가 붙게 되면 오래된 순으로 가져가게 됨

- 컨슈머가 record들을 가져가도 데이터는 삭제되지 않음, 새로운 컨슈머가 붙었을 때 다시 0번 부터 가져갈 수 있음(컨슈머 그룹이 달라야하고, auto.offset.reset=earlliest 여야함)

  #### 파티션이 두개이상

  - 프로듀서가 데이터를 보낼 때 키를 지정할 수 있음
    1) 키가 null이고, 기본 파티셔너 사용 할 경우 -> 라운드 로빈(Round robin:하나씩 나누어짐)으로 할당
    2) 키가 있고, 기본파티셔너 -> 키의 해시(hash) 값을 구하고, 특정 파티션에 할당
  - 파티션을 늘리는 것은 가능, 다시 줄일 수는 없음
  - 파티션을 늘리면  컨슈머개수를 늘려 데이터 처리를 분산시킬수 있음

  #### 파티션의 record는 언제 삭제되는가?

  - log.retention.ms : 최대 record 보존 시간
  - log.retention.byte: 최대 record 보존 크기(byte)

  

## kafka producer

- 데이터를 카프카에 보내는 역할

- 방대한 양의 클릭 로그들을 대량으로, 실시간으로 카프카에 적재할 때 사용 할 수 있다.

- 데이터를 kafka topic에 생성하는 역할을 한다

  #### Producer role

  - Topic에 해당하는 메시지를 생성
  - 특정 Topic으로 데이터를 publish
  - 처리 실패 여부/재시도

```java
// gradle
compile group: 'org.apach.kafka', name: 'kafka-clients', version: '2.3.0'
    
// maven
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>2.3.0</version>
</dependency>
```



- 카프카 클라이언트인 컨슈머와, 프로듀서를 사용하기 위해서는 아파치 카프카 라이브러리를 추가해야 함
- 라이브러리는 그래들이나 메이븐 같은 도구를 사용하여 편리하게 사용
- 카프카 클라이언트를 디펜던시로 잡을 때 주의점 : 버전

- 브로커 버전과 클라이언트 버전의 하위호환성이 완벽히 지원하지 않음



#### Producer.send

```java
producer.send(new ProducerRecord<String, String>('click_log', 'login'));
```

- 카프카는 key를 특정한 hash 값으로 변경시켜 파티션과 1대1 매칭시킨다
- 중간에 파티션을 추가하면, key 와 파티션의 매칭이 깨지기 때문에 연결이 보장되지 않는다





## 핵심요소 3가지(broker, replication:복제, ISR)

- 카프카 운영하는데 아주 중요한 역할을 함



- 클러스터에서 서버에 장애가 생길때 가용성을 보장하는 가장 좋은 방법이 복제이다



#### 카프카 broker

- 카프카가 설치되어 있는 서버 단위
- 보통 3개 이상의 broker로 구성하여 사용 권장
- 파티션이 1개, replication이 1인 topic이 존재, broker가 3대라면
  브로커 3대중 1대에 해당 토픽의 정보(데이터)가 저장된다



<img src="아파치 카프카.assets/image-20201124012850144.png" alt="image-20201124012850144" style="zoom:67%;" />

<img src="아파치 카프카.assets/image-20201124012854183.png" alt="image-20201124012854183" style="zoom:67%;" />

<img src="아파치 카프카.assets/image-20201124012857541.png" alt="image-20201124012857541" style="zoom:67%;" />

- 브로커 개수에 따라서 replication 개수가 제한됨
- 원본은 leader partion, 복제본은 follower particion
- 이 둘을 합쳐서 ISR. 즉, In Sync Replica 라고 볼수 있다



#### why replicate?

- partition의 고 가용성을 위해 사용